Thanks for the thorough reviews. Several reviewers requested we clarify the paper’s contributions. First, emphasizing reviewer F’s observation, synchronous function calls that can time out and return a continuation are new to unmanaged languages. Second, selective relinking and libset-granularity isolation are novel and enable us to support sub-process cancellation, something that is difficult atop today’s systems stack. Third, unlike prior efforts towards preemptive userland thread libraries (i.e., many-to-many noncooperative schedulers), ours eschews limitations such as disallowing legacy code (RT) or disabling preemption during legacy code (Shinjuku).

Our heap model was a common source of confusion, possibly because we split discussion of it between sections 1 and 5.5. To avoid the object lifetime challenges arising from maintaining multiple heaps, we use a single shared heap for the entire program. We implement this by whitelisting libc’s allocator-related functions as uncopyable so all calls thereto are routed to the starting libset. In contrast, each libset uses its own private copy of most of libc. We will clarify this.

Two reviewers asked where library copying may alter program semantics. This can happen whenever a library is used to share a resource that cannot be cloned, whether internal to the library (e.g., an in-memory data structure) or external to the process (e.g., a network adapter). The reviews identified examples of each case:  To the first, we note that a library implementing a key-value store only provides a shared resource if its interface is nonreentrant; otherwise, the application may share the pointer or handle between libsets. As a concrete example, modern data structures such as glibc’s hsearch\_r() may be shared between libsets, whereas legacy global ones such as POSIX’s hsearch() appear disjoint when viewed from each scope; the latter interface style is rare today. Second, libc’s stdio.h exemplifies sharing a device: the file descriptor. This does mean that performing I/O from multiple libsets can introduce interleaving.  It is rare, because each libc will use a separate buffer, but could require special handling to guard the underlying file descriptor.

Re: questions about the evaluation: We believe it infeasible to comprehensively evaluate all preemptible function use cases within the conference paper format precisely because they represent such a broadly-applicable abstraction. We presented thorough microbenchmarks and devoted our additional evaluation effort to situations where preemptible functions enable functionality difficult or impossible to achieve otherwise. These are function cancellation and preemptive userland scheduling, hence our choice of long-running image decoding and bimodally-distributed Web requests, respectively.

Below we enclose additional responses to reviewers’ specific questions and comments in case they are useful, but are beyond the response limit for the rebuttal, so you can stop here!

**Reviewer A: I would encourage you to set out explicitly in the paper a set of criteria by which programmers can depend on pre-emption working as intended -- or at least a conservative approximation to this, which can be considered independently from the details of the current implementation.**
The library copying approach preserves program semantics if there is not an underlying shared object (whether it be data or external) hidden behind the scenes, as described in the rebuttal proper.

**Reviewer B: I think the approaches described are actually more general. I.e., the reason for preemption doesn’t need to be a timeout, but could be real-time scheduling or priority preemption. Am I mistaken? If not, generalizing the point (and perhaps using timer-preemption as a simple use case) would be helpful.**
Yes, they are indeed more general. Libset isolation works regardless of the preemption mechanism, and any external source of control transfer can be used to invoke the machinery we describe herein.

**Reviewer B: What is a worst-case execution for libgotcha? Would it be cases when there are deep call stacks of different lib sets?**
Data, not instructions, have the biggest effect on libgotcha’s overhead. As shown in Table 3, global variable accesses currently incur high latency under libgotcha; as such, any workload whose critical path involves frequent accesses to non-static globals via dynamic symbols is likely to perform poorly. That is not to say we do not add overhead to functions: the table shows that we raise the latency of each dynamically-resolved function call by an order of magnitude. In terms of multiple libsets, the table also shows that the implicit libset switch due to an uncopyable/whitelisted function costs about the same as a function call. So roughly speaking, the overhead we impose on a deeply-nested call stack is proportional to the sum of the number of dynamically-resolved calls and the number of libsets traversed.

**Reviewer B: The evaluation shows situations when libturquoise provides benefits. Are there (synthetic, even?) cases when it doesn't? E.g., if calls are never preempted?**
Given that libturquoise exists to add preemption to an otherwise unchanged tokio-threadpool, you are correct to identify that it is not useful in cases where tasks are never preempted.

**Reviewer C: The work doesn't clearly resolve many concerns about user-level concurrency, such as blocking system calls.**
Our main goal is to provide pausing and cancellation without requiring asynchrony. A preemptible function that makes blocking system calls is an example of a situation where asynchrony is probably desired; this is possible by using a thread library in concert with libinger. Our own libturquoise benefits from the Rust Tokio project’s prior work on blocking syscalls: whenever a worker thread makes a blocking call, its kernel thread is reclassified as a special blocking thread and a new kernel thread is allowed to join the pool to maintain the prescribed number of active threads. Of course, Tokio can only identify such blocking calls if the user calls them via its own future-based wrappers; doing so in the general case would require an active kernel notification mechanism such as scheduler activations. Although unable to catch direct uses of the syscall instruction, one potential area of future work might be to extend libgotcha with another whitelist so that it could issue a callback to warn compatible thread libraries when a library function was about to block, in a simpler version of what is described in section 5.5.

**Reviewer C: For your pthread\_create test, do you allow pthread\_create to use pre-allocated heaps, similarly to how launch pre-allocates heaps?**
It is stacks, not heaps, that we pre-allocate for use by launch(); we will make sure to clarify this. See also our discussion of the shared heap in the rebuttal proper.

**Reviewer D: Libinger allocates 2MB fixed-size stack on heap in advance; thus it hurts memory space utilization despite reusable stack. Also, the big fixed-size stack can be an open door to stack overflow-type attacks.**
Preallocating the stacks was an implementation shortcut taken to accelerate prototyping, and is not fundamental. We plan to replace it with a pool allocator.
Should physical memory utilization or stack overflows become a major concern, one could easily replace the 2MB stack allocations with mmap() calls for significantly larger but non-prefaulted regions; in this way, the stacks would be able to grow via demand paging.

**Reviewer D: I doubt that this system is really necessary, because the synchronous preemptive function interface on the caller's thread is only better for non-reentrant function, not the other functions.**
On the contrary, it gives you a mechanism to easily pause and cancel any synchronous function call without involving a thread scheduler, thereby saving you the loss of control and internal overhead inherent to the state of the art approach. This is equally relevant to reentrant functions.

**Reviewer E: The scope of the evaluation is limited and does not account for key metrics such as ease of use and the effort required to port existing applications to the proposed paradigm. It seems like your proposed abstractions are useful but also not user friendly and hence error-prone.**
The hyper Web server uses tokio-threadpool for scheduling; because the changes we made to the thread library are transparent, making it preemptive was as easy as building against libturquoise instead. In fact, we didn’t even check out the hyper codebase.
In the libpng benchmark, calling the decode functions using the fork()/sigtimedwait() approach took 25 lines of Rust code; this was without implementing any mechanism for communicating the resulting buffers back to the main process. The launch()/cancel() approach took 20 lines, including implementing a reaper thread to move libset reinitialization off the critical path. Note that due to their use of the libpng C library and in order to achieve peak performance, both benchmarks include blocks of unsafe Rust.

**Reviewer E: I am wondering to what extent you propose to alter the current programming paradigm of the languages you target. It is clearly useful that you can have a timed function that returns a context that can later be resumed. It also seems like it complicates programming substantially without additional safeguards. Can you speculate/discuss implications on bug density/ software reliability?**
From the programmer’s perspective, most of the complexity we introduce is no different than that present in any concurrent program: barring some incompatible library, the only exception is the pause() discussion in section 3.2. Although less language agnostic, it would be easy to hide this new complexity from the programmer by providing a mutex wrapper implementing the familiar lock operation with a call to pause(). Admittedly, concurrent programming has posed challenges for the community for decades, but recent languages such as Rust have made strides in statically identifying concurrency bugs, and we benefit from this prior work.

**Reviewer E: I didn't get a good sense of the challenges you faced and your key contributions.**
See the rebuttal proper for a list of our contributions. A common theme of the challenges we faced was that the system interacts with low-level details of the POSIX API, the AMD64 ABI (application binary interface), ELF (executable and linkable format) binaries and libraries, and dynamic linking. This required developing great familiarity with their intricacies. To name a few examples: Central to libinger is the need to restore a POSIX context (continuation) saved from within the preempting signal handler, but this is not directly allowed due to a corner case in the specification of the context API and a resulting lack of support by implementations including glibc; we devised an alternate scheme of indirecting through an intermediate signal handler. We also needed to receive timer signals on specific threads, but the kernel directs them to an arbitrary thread within the process; we addressed this by allocating signal numbers from a pool. Section 5.2 observes that achieving proper scoping semantics requires selectively relinking only those dynamic symbol references that occur outside the defining library, but some function calls are resolved lazily the first time they are called; implementing this requirement involved devising an algorithm that resolves such functions early when this is necessary to disambiguate their location. On the topic of lazy symbol resolution, the dynamic linker was initially clobbering our modified GOT entries when memoizing lazy bindings, and fixing this problem required rewriting the ELF relocation table to trick the linker into saving the resolved address in a shadow table instead. When implementing selective relinking, we had to be careful to preserve pointer comparison semantics when a program passes pointers to dynamically-resolved symbols between libraries; a past related bug caused a glibc security feature to abort the program due to discrepancies in FILE objects.

**Reviewer F: Does the implementation support thread\_local/\_\_thread?**
Yes, with the following caveat: Ulrich Drepper’s specification ELF Handling for Thread-Local Storage defines the AMD64 ABI’s four TLS access models. Of these, the general dynamic and local dynamic model assign module identifiers at library load time, which means that each copy of a library has a different such identifier. In order to support cross-module symbol references, these models use a support function called \_\_tls\_get\_addr() to resolve addresses; this function is whitelisted as part of the dynamic linker, making it uncopyable so that preemption will not corrupt the TLS metadata. There are two other models, initial exec and local exec, that omit dynamic module addressing as an optimization, which means using them to access TLS variables does not respect libgotcha’s next libset setting. However, initial exec is not general enough to be used by libraries that do not request it; and local exec is only applicable to the executable itself, and is only the default when the application is compiled with COPY relocations enabled, as documented in the -ftls-model discussion in gcc(1). An earlier version of section 5 explained that COPY relocations are an optimization incompatible with our desired global variable semantics and mentioned that upon detecting any, libgotcha issues a warning that the executable must be recompiled with the -fpic flag to disable them. This discussion was removed for space reasons, but we can restore and expand it with details about the TLS.

**Reviewer F: The distinction and division of responsibility between libinger and libturquoise (and libgotcha) is not immediately clear.**
We are sorry we failed to articulate this, and will try to clarify in the next revision. libinger implements preemptible functions: launch(), resume(), cancel(), and pause(). libturquoise is a preemptive version of the tokio-threadpool (futures) thread library. libgotcha implements library isolation at the granularity of libsets, which makes it possible to provide abstractions such as libinger’s without having to treat “the rest of the program… as a signal handler,” as discussed in section 3.1.

**Reviewer F: If library M depends on library N, then, transitively, N's data must be cloned when M is cloned?**
Yes, cloning occurs at libset granularity. This is necessary because we defer library loading to the dynamic linker, and it loads all dependencies of a given library before initializing it.

**Reviewer F: … it would seem a deep copy is required but only a shallow copy is feasible with the information at hand.**
Characterizing library copying as a question of deep vs. shallow copying seems to miss the point: what we do is copy the library as it appears immediately after loading by the dynamic linker, not as it appears after the application has used it. Keep in mind that any structures a library allocates on the caller stack or the shared heap are owned by the process as a whole, and not any individual libset or library.

**Reviewer F: Are there any synchronization constructs or system calls that don't readily respond to asynchronous timer signals or, if the signal is delivered, can't be safely longjmp()ed out of?**
As far as we know, the only way to stop a timer signal is via the facilities of signal.h or time.h, and their corresponding system calls. The signal(7) manpage assures us, “If a signal handler is invoked while a system call or library function call is blocked, then either: the call is automatically restarted after the signal handler returns; or the call fails with the error EINTR.” We install our signal handler with the SA\_RESTART flag to sigaction() to request the former behavior and make the syscall interruptions we cause as transparent as possible. By definition, any correct synchronization construct should protect against any preemption point. We have striven to whitelist as uncopyable all glibc interfaces that manipulate process-wide state, so these will never be preempted. Because selective relinking isolates nonreentrant state, any concurrency bugs introduced by using preemptible functions should be the result of either incorrect synchronization by the programmer or underlying shared resources external to the program.

**Reviewer F: Is "selective relinking" accomplished via the rtld.so "audit" facility?**
No. We considered using the interface described in rtld-audit(7), but doing so requires defining the LD\_AUDIT environment variable before invoking your program. We view selective relinking as an implementation detail (albeit a novel one) underlying the preemptible functions abstraction, and therefore felt that launching libinger-based programs should not require the user to do anything special. As such, libgotcha uses a shared library constructor to implement selective relinking manually as soon as the dynamic linker loads it into the process image.
