\section{Related Work}
\label{sec:related}

\mk{Maybe reverse use of bold and italics?}

\begin{table*}
\small
\begin{tabular}{c||c|c|c|c|c|c}
&& Divorces from & \multicolumn{2}{c|}{Dependencies} & \multicolumn{2}{c}{Third-party code support} \\
System & Preemptive & threading & In userland & Works without GC & No redesign & No recompilation \\
\hline
\textit{Scheme engines} & \checkmark* & \checkmark & \checkmark && $\dagger$ & --- \\
\textit{Lilt} && \checkmark & \checkmark && $\dagger$ & \\
\textit{goroutines} &&& \checkmark &&& \\
\textit{RT library} & \checkmark && \checkmark & \checkmark && \\
\textit{Shinjuku} & \checkmark &&& \checkmark && \\
\hline
\textit{libinger} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark
\end{tabular}

\centering{* = the language specification leaves the interaction with blocking system calls unclear} \\
\centering{$\dagger$ = assuming the third-party library is written in a purely functional (stateless) fashion}
\caption{Systems providing intra-process bounded execution time}
\label{tab:related}
\end{table*}

A number of past projects (Table~\ref{tab:related}) have sought to provide
bounded-time execution of chunks of code at a sub-process granularity.
For the purposes of our discussion, we
refer to a portion of the program whose execution should be bounded as \textbf{timed
code} (a generalization of a preemptible function); exactly what form this takes
depends on the system's interface.

Their interfaces notwithstanding, perhaps the systems' most distinguishing
characteristic is the mechanism by which they enforce execution bounds.  At one end
of the spectrum are \textbf{cooperative} multitasking systems where
timed code voluntarily cedes such use of the CPU to another
task via a runtime check.  (This is often done implicitly, a simple example being a
system that injects code to check
whether the timed code has expired at the beginning of every one of its function
calls.)  The other extreme is filled by \textbf{preemptive} systems where the CPU
interrupts the timed function and transfers control to a scheduler routine (e.g., via
an interrupt service routine or signal handler, possibly within the language's VM).

\dga{May want to cut long-running CPU instructions unless we can come up with a
modern (i.e., non-VAX) example.  Furthermore, it invites disagreement.}

The cooperative approach tends to be unable to interrupt two classes of timed code:\@
(1) \textbf{blocking-call} code sections that cause
long-running kernel traps (e.g., by making I/O system calls),
thereby preventing the interruption logic from being run; and (2)
\textbf{excessively-tight loops} whose body does not contain any yield points (e.g.,
spin locks or long-running CPU instructions).
Although some cooperative systems refine their approach with mechanisms
to tolerate either blocking-call code sections~\cite{www-golang} or excessively-tight
loops~\cite{vanderwaart:cmucs2006}, we're not aware of any that are capable of
handling both
cases.

One well-known early example of timed code was the \textit{engines} feature of
the Scheme 84 language~\cite{haynes:iucs1984}.  The feature added an \texttt{engine}
keyword that behaved similarly to the \texttt{lambda} one, but created a ``thunk''
accepting as an argument the number of ticks (abstract time units) it should run for.
In their interface, the caller also supplied a callback function to receive the
timed code's return value upon successful completion.  Like the rest of the
Scheme language, engines were stateless:\@ whenever one ran out of computation time,
it would return a new engine representing the new execution point.  The
implementation of engines relied heavily on Scheme's managed runtime, with ticks
corresponding to virtual machine instructions and cleanup handled by the garbage
collector.  The VM dependency was not fundamental, however, as the literature notes
that timer interrupts could have been used instead.

\dga{In the early days of green threading, runtimes (e.g., libasync) would use
complex and fragile handling of blocking calls, proxying them to \texttt{select()}
or similar.  Might be a good footnote to pacify the old, crotchety reviewer.}

In 2006, C.\@ Joseph Vanderwaart introduced a language, \textit{Lilt}, for writing
programs with statically-enforced timing policies~\cite{vanderwaart:cmucs2006}.  The
language's compiler tracks the possible duration of each path through the program and
and inserts yield operations wherever its time might have expired.  Although this
approach requires knowing the execution limit at compile time, the compiler is able
to handle excessively-tight loops thanks to its awareness of backward jumps.
Blocking-call functions remained a challenge, however:\@ handling them would have
required
operating system support, reminiscent of \textit{Singularity}'s static language-based
isolation~\cite{hunt:msr2005}.

Some recent languages offer userland threading, which could be used to support timed
code.  One such example is the Go language's~\cite{www-golang} \textit{goroutines}.
The language's runtime is responsible for scheduling multiple such user
threads per kernel thread, which is performed cooperatively by conditionally yielding
at function call points.  This has long caused problems with tight loops, with the
traditional workaround being to manually add calls to the \texttt{runtime.Gosched()}
yield function~\cite{www-golang-tightloop}.

All the solutions discussed thus far rely on languages with a heavyweight,
garbage-collecting runtime.  However, some recent systems have sought
to provide timed functions in a language-agnostic fashion that minimizes such
dependencies.  One example is the userland C-language thread library for realtime
systems (here, ``\textit{RT}'') developed by Mollison and
Anderson~\cite{mollison:rtas2013}, which performs
preemption using timer interrupts, as proposed in the early Scheme engines
literature.  They install a time-based signal handler responsible for both scheduling
tasks and migrating them between cores.  Thanks to their lightweight runtime, they
are able to achieve average overall scheduling latencies in the tens of microseconds.
However, as we'll see shortly, this comes with a huge usability cost for developers.

\textit{Shinjuku}~\cite{Kaffes:nsdi2019} is an operating system designed to perform
preemption at microsecond scale.  Built on the Dune framework~\cite{Belay:osdi2012},
it runs tasks on a pool of worker threads controlled by a single centralized
dispatcher thread.  The latter polices how long each task has been running and
sends an inter-processor interrupt (IPI) to any worker whose task has been running
for longer than permitted.  The authors study the cost of IPIs and the overheads
imposed by performing them within a VT-x virtual machine, as required by Dune.  They
then implement optimizations to reduce these overheads at the expense of Shinjuku's
isolation from the rest of the system.

It is challenging to support timed code within a system that doesn't assume
concurrency, because programs might use shared state.  Whenever we have two
functions,
\texttt{foo()} and \texttt{bar()}, that access the same state, and we interleave at
runtime a call to \texttt{bar()} in the middle of the execution of \texttt{foo()},
the result is undefined behavior.  In the C language, it's important to consider
shared state whenever writing a signal handler, which may be called at any point
in the program's execution.  The POSIX standard defines the term \textbf{async-signal
safe} to
refer to a function that is safe to invoke from a signal
handler~\cite{signal-safety-manpage}; the list of standard library functions required
to exhibit this property notably excludes all dynamic memory allocator functions such
as \texttt{malloc()}.  Note that async-signal safety is a stronger requirement than
thread safety:\@ the code may interrupt itself, and if this happens within a critical
section, traditional approaches to thread safety will merely cause a deadlock.
Unfortunately, shared state is a common feature of libraries written in C, which
often rely on it for error handling (e.g., libc's \texttt{errno} variable), resource
allocation and assignment, caching and memoization, etc.

Because eliminating shared state from most libraries requires substantial
interface-level (breaking API) changes, the shared state issue prevents existing
systems from calling into third-party code without rewriting it.  Scheme engines and
Lilt skirt this issue by only supporting functional code, which cannot have shared
state.  Because of its focus on realtime embedded systems, RT makes an assumption
that the timed code in its threads will avoid shared state; this mostly precludes
calls to third-party libraries, although the system supports the dynamic memory
allocator by treating it as specifically nonpreemptible.  Rather than dealing with
shared state itself, Shinjuku asks application authors to annotate any code with
potential concurrency concerns using a nonpreemptible \texttt{call\_safe()} wrapper.
Finally, although Go is able to preempt most goroutines written directly in Go, a
goroutine that makes any foreign calls to other languages is treated as
nonpreemptible by the runtime's scheduler~\cite{www-golang-fficall}.
