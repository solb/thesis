\section{Related work}
\label{sec:related}

\begin{table*}
\ifdefined\mytableistoobig
	\scriptsize
\else
	\small
\fi
\begin{tabular}{c||c|c|c|c|c|c}
&&& \multicolumn{2}{c|}{Dependencies} & \multicolumn{2}{c}{Third-party code support} \\
System & Preemptive & Synchronous & In userland & Works without GC & Preemptible & Works without recompiling \\
\hline
\textit{Scheme engines} & \checkmark* & \checkmark & \checkmark && $\dagger$ & \checkmark \\
\textit{Lilt} && \checkmark & \checkmark && $\dagger$* & --- \\
\textit{goroutines} &&& \checkmark && $\dagger$* & --- \\
$C\forall$ & \checkmark && \checkmark & \checkmark & $\dagger$* & --- \\
\textit{RT library} & \checkmark && \checkmark & \checkmark && \checkmark \\
\textit{Shinjuku} & \checkmark &&& \checkmark & $\dagger$ & \\
\hline
\textit{libinger} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark
\end{tabular}

\vspace{12pt}
\centering{\checkmark* = the language specification leaves the interaction with blocking system calls unclear} \\
\centering{$\dagger$ = assuming the third-party library is written in a purely functional (stateless) fashion} \\
\centering{$\dagger$* = the third-party code must be written in the language without foreign dependencies} \\
\centering{(beyond simple recompilation, this necessitates porting)}
\vspace{6pt}
\caption{Systems providing timed code at sub-process granularity}
\label{tab:related}
\end{table*}

A number of past projects (Table~\ref{tab:related}) have sought to provide
bounded-time execution of chunks of code at sub-process granularity.
For the purpose of our discussion, we
refer to a portion of the program whose execution should be bounded as \textbf{timed
code} (a generalization of a preemptible function); exactly how such code is
delineated depends on the system's interface.

Interface notwithstanding, the systems' most distinguishing
characteristic is the mechanism by which they enforce execution bounds.  At one end
of the spectrum are \textbf{cooperative} multitasking systems where
timed code voluntarily cedes the CPU to another
task via a runtime check.  (This is often done implicitly; a simple example is a
compiler that injects a conditional branch
at the beginning of any function call from timed code.)
Occupying the other extreme are \textbf{preemptive} systems that externally
pause timed code and transfer control to a scheduler routine (e.g., via
an interrupt service routine or signal handler, possibly within the language's VM).

The cooperative approach tends to be unable to interrupt two classes of timed code:\@
(1) \textbf{blocking-call} code sections that cause
long-running kernel traps (e.g., by making I/O system calls),
thereby preventing the interruption logic from being run; and (2)
\textbf{excessively-tight loops} whose body does not contain any yield points (e.g.,
spin locks or long-running CPU instructions).
Although some cooperative systems refine their approach with mechanisms
to tolerate either blocking-call code sections~\cite{www-golang} or excessively-tight
loops~\cite{vanderwaart:cmucs2006}, we are not aware of any that are capable of
handling both
cases.

One early instance of timed code support was the \textit{engines} feature of
the Scheme 84 language~\cite{haynes:iucs1984}.  Its interface was a new
\texttt{engine}
keyword that behaved similarly to \texttt{lambda}, but created a special ``thunk''
accepting as an argument the number of ticks (abstract time units) it should run for.
The caller also supplied a callback function to receive the
timed code's return value upon successful completion.  Like the rest of the
Scheme language, engines were stateless:\@ whenever one ran out of computation time,
it would return a replacement engine recording the point of interruption.  Engines'
implementation relied heavily on Scheme's managed runtime, with ticks
corresponding to virtual machine instructions and cleanup handled by the garbage
collector.  Although the paper mentions timer interrupts as an alternative, it does
not evaluate such an approach.

\textit{Lilt}~\cite{vanderwaart:cmucs2006} introduced a language for writing
programs with statically-enforced timing policies.
Its compiler tracks the possible duration of each path through a program and
inserts yield operations wherever a timeout could possibly occur.  Although this
approach requires assigning the execution limit at compile time, the compiler is able
to handle excessively-tight loops by instrumenting backward jumps.
Blocking-call functions remained a challenge, however:\@ handling them would have
required
operating system support, reminiscent of \textit{Singularity}'s static language-based
isolation~\cite{hunt:msr2005}.

Some recent languages offer explicit userland threading, which could be used to
support timed
code.  One example is the Go language's~\cite{www-golang} \textit{goroutines}.
Its runtime includes a cooperative scheduler that conditionally yields
at function call sites.  This causes problems with tight loops, which require the
programmer to manually add calls to the \texttt{runtime.Gosched()}
yield function~\cite{www-golang-tightloop}.

The solutions described thus far all assume languages with a heavyweight,
garbage-collected runtime.  However, two recent systems seek
to support timed code with fewer dependencies: the $C\forall$
language~\cite{delisle:wcs2018} and a C thread library for realtime systems (here,
``\textit{RT}'') developed by Mollison and Anderson~\cite{mollison:rtas2013}.
Both perform preemption using timer interrupts, as proposed in the early Scheme
engines literature.  They install a periodic signal handler for scheduling
tasks and migrating them between cores, a lightweight approach that achieves
competitive scheduling latencies.
However, as explained later in this section, the compromise is interoperability with
existing code.

\textit{Shinjuku}~\cite{Kaffes:nsdi2019} is an operating system designed to perform
preemption at microsecond scale.  Built on the Dune framework~\cite{Belay:osdi2012},
it runs tasks on a worker thread pool controlled by a single centralized
dispatcher thread.  The latter polices how long each task has been running and
sends an inter-processor interrupt (IPI) to any worker whose task has timed out.
The authors study the cost of IPIs and the overheads
imposed by performing them within a VT-x virtual machine, as required by Dune.  They
then implement optimizations to reduce these overheads at the expense of Shinjuku's
isolation from the rest of the system.

As seen in Section~\ref{sec:intro}, nonreentrant interfaces are
incompatible with externally-imposed time limits.  Because such interfaces are
prolific in popular dependencies, no prior work allows timed code to transparently
call into third-party libraries.  Scheme engines and
Lilt avoid this issue by only supporting functional code, which cannot have shared
state.  Go is able to preempt goroutines written in the language itself, but a
goroutine that makes any foreign calls to other languages is treated as
nonpreemptible by the runtime's scheduler~\cite{www-golang-fficall}.
The C$\forall$ language's preemption model is only safe for functions guarded
by its novel monitors:\@ the authors caution that ``any challenges that are not [a
result of extending monitor semantics] are considered as solved problems and
therefore not discussed.''
With its focus on realtime embedded systems, RT assumes
that the timed code in its threads will avoid shared state; this assumption mostly
precludes
calls to third-party libraries, though the system supports the dynamic memory
allocator by treating it as specifically nonpreemptible.  Rather than dealing with
shared state itself, Shinjuku asks application authors to annotate any code with
potential concurrency concerns using a nonpreemptible \texttt{call\_safe()} wrapper.
