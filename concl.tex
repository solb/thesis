\chapter{Conclusions and continuations}
\label{chap:thatsawrap}

At the start of this \thesis, we set out to substantiate this thesis statement:
\begin{quote}
\input{statement}
\end{quote}

We now break this down and briefly recap our work pertaining to each of its claims
(Section~\ref{sec:thatsawrap:contributions}), discuss applications and directions for
future work (Section~\ref{sec:thatsawrap:applications}), review a selection of the
technical challenges we had to overcome (Section~\ref{sec:thatsawrap:challenges}),
and distill a few lessons for future systems builders
(Section~\ref{sec:thatsawrap:lessons}).


\section{Contributions}
\label{sec:thatsawrap:contributions}

The abstract expands on the thesis statement:

\begin{quote}
\input{abstract}
\end{quote}

It makes specific references to key contributions; we now further expand on each of
these and give pointers back to the relevant chapters and sections.

\paragraph{Novel programming abstractions for isolation of both time and memory}
These abstractions are lightweight preemptible functions and selective relinking.
They are introduced in Chapter~\ref{chap:functions} and Chapter~\ref{chap:libgotcha},
respectively.

\paragraph{Preemption at sub-millisecond timescales}
We found in Section~\ref{sec:libinger:quantum} that the modern systems stack is
capable of supporting timer signals with periods on the order of microseconds.  We
argued that the design of lightweight preemptible functions is compatible with
preemption quanta down to at least the tens of microseconds, with scaling limited by
increasing CPU time overheads.  We also demonstrated that the latency of invoking a
preemptible function is in the same order of magnitude
(Section~\ref{sec:libinger:ueval}).  This is one order of magnitude faster than
forking a new process and two orders of magnitude finer than the typical operating
system preemption quantum.

\paragraph{Tasks defined at the level of a function call}
Both lightweight preemptible functions and selective relinking explicitly treat
function calls as an isolation boundary.  The former expresses this boundary by
asking the programmer to annotate preemptible functions by invoking them with a
wrapper function (Section~\ref{sec:libinger}); the latter does so by intercepting
calls to dynamically-linked functions based on the context of the call
(Section~\ref{sec:libsets}) and knowledge of specific functions that cannot be
protected solely through memory isolation (Section~\ref{sec:libgotcha:unint}).  That
our system understands function calls is significant because traditionally both
preemption and memory isolation have operated exclusively at the granularity of a
kernel thread.

\paragraph{New functionality for application programmers}
It is worth emphasizing that our abstractions are available in userland and
accessible to any programmer experienced with concurrency.  They expose powerful APIs
that we summarize in Listings~\ref{lst:ingerfullapi} and \ref{lst:ingerrustapi}
(lightweight preemptible functions) and Listings~\ref{lst:gotchaapi} and
\ref{lst:gotchacbapi} (selective relinking).  The preemptible functions Rust API is
even type safe and usable in contexts where the standard library does not allow
thread spawns (Chapter~\ref{chap:libinger}).  Preemptible functions themselves serve
as an example application for selective relinking, and
Chapters~\ref{chap:strobelight} and
\ref{chap:microservices} present case studies in building systems atop preemptible
functions.  Simpler applications include detection of pathological cases such as
adversarially-constructed compressed images (Section~\ref{sec:libinger:bombs}) and
graceful degradation by dropping video frames.

\paragraph{Unmanaged systems programming languages}
Unlike prior art, our abstractions are restricted neither to purely functional code
nor to managed languages with heavyweight, garbage-collected runtimes
(Section~\ref{sec:related}).  In principle, their only operating system and runtime
requirements are timer signals (Section~\ref{sec:libinger:signals}) and dynamic
linking (Section~\ref{sec:libgotcha:portability}).\footnote{It helps to also have
exception handling, as per Section~\ref{sec:ingerc:raii}.}  We officially support the
low-level C and Rust systems programming languages.  We have tried to keep the API
language agnostic, and the fact that many languages include C foreign-function
interfaces means that some of them may already be able to use preemptible functions
out of the box.

\paragraph{Without requiring changes to the existing systems stack}
We implement everything entirely in userland by building on existing abstractions
such as dynamic linking, memory protection, POSIX signals and timers, and exception
handling.  Where we alter the behavior of the dynamic linker and C runtime, we make
those changes at load time (Section~\ref{sec:gotchainit}).  (While we do not in
principle require a custom glibc, one must rebuild from source with a different
configuration macro for full functionality, as explained in
Section~\ref{sec:libgotcha:scalability}.  The only component of the system that
absolutely requires the developer of an application to rebuild its dependencies is
cancellation resource cleanup, per Sections~\ref{sec:ingerc:start},
\ref{sec:ingerc:boundary}, and \ref{sec:ingerc:cancellation}.)

\paragraph{Synchronous invocation}
Unlike threads and callback-based futures, preemptible functions are invoked
synchronously.  This eliminates the need for an external scheduler and the associated
overhead in cases where the programmer is willing to manually manage which
preemptible function to launch or resume next (Chapter~\ref{chap:functions}).  It
also allows a preemptible closure to safely capture local variables in Rust
(Chapter~\ref{chap:libinger}).

\paragraph{Compose naturally with existing concurrency abstractions}
Both abstractions are usable in multithreaded contexts.  In fact, one can even take a
paused preemptible function that was executing one one kernel thread and resume it
on a different one (Section~\ref{sec:libinger:tcbs}), a property that allows
schedulers to treat preemptible functions like any other task.  Preemptible functions
can be used to construct preemptible futures (Section~\ref{sec:libturquoise:prefuts})
and even mutexes with \texttt{await}-style call with current continuation semantics
(Section~\ref{sec:libinger:locks}).

\paragraph{Asynchronous cancellation of threads}
It has long proven difficult to cancel running threads, both at the operating system
level (Section~\ref{sec:functions:motivation}) and at the language level
(Section~\ref{sec:strobelight:cancellation}).  We
discover that we can leverage the memory isolation provided by selective relinking to
enable asynchronous cancellation of POSIX threads, a feature that is almost unusable
as shipped in the Unix operating system and its clones
(Chapter~\ref{sec:safety:acsafe}).  Although resource leaks remain a problem
(Section~\ref{sec:safety:thread}), it may be possible to address them for languages
conforming to RAII (Chapter~\ref{chap:ingerc}).

\paragraph{Preemptive thread libraries in userland}
By modifying the thread pool from a Rust futures executor to transparently wrap
tasks in preemptible futures, we have created arguably the first general-purpose
preemptive thread library implemented entirely in userland.  Details are in
Chapter~\ref{chap:libturquoise}.


\section{Applications and future work}
\label{sec:thatsawrap:applications}

This \thesis leaves ample opportunity for future work on lightweight preemptible
functions and selective relinking.  Possible directions include exploring other
applications for our abstractions, conducting a deeper investigation of our example
applications, making performance improvements, lifting scalability restrictions,
adding defense in depth, improving application compatibility, and contributing more
of our discoveries upstream.

There are plenty of possible applications we have not explored.  We have focused on
preemptible functions that use timeouts as a resource limit, but the underlying
fine-grained preemption we developed to support them is actually more general.  One
can imagine applying it to real-time scheduling or imposing quotas based on resources
other than time, such as data transferred or number of page faults.
Chapter~\ref{chap:microservices} proposed the use of preemptible functions to merge
multiple cloud tenants' microservices into a single worker process, a technique that
could be applied to locally-running programs as well.  One could even write a tool
that took two or more dynamically-linked position-independent executables and merged
them into a single application that included in-process scheduling.  Selective
relinking, with its ability to intercept function calls and issue notification
callbacks, surely has applications in aspect-oriented programming.  Its techniques
could be applied to other problems as well, such as allowing applications to depend
on more than one version of a dynamic library.  Both abstractions enable many new use
cases, and we are sure there are many we have not thought of.

Those applications that we have explored also merit deeper study.
Section~\ref{sec:safety:assafe} demonstrated how selective relinking can be used to
lift the primary safety restriction on signal handlers.  Our treatment was brief, but
in our opinion it represents such a significant improvement to the signal abstraction
that it would be worth carrying beyond the prototype stage.  In creating an
implementation suitable for deployment, one might explore isolating each signal
handler from the others or defining a completely safe interface for signal handling
in Rust or another language with a sound type system.
Section~\ref{sec:safety:acsafe} gave a preliminary implementation of asynchronous
thread cancellation, a feature that operating systems and programming languages alike
have long struggled to support.  Refining this prototype might involve fixing the
resource leaks problem by integrating the automatic cleanup approach we sketched in
Chapter~\ref{chap:ingerc}.
We think that preemptible futures and preemptive userland threading hold enormous
potential for building scalable systems with better resistance to denial of service
attacks.  We implemented these concepts before we had proper support for thread-local
storage and at a time when the Rust ecosystem was in flux because the language was
just stabilizing futures and async/await.  As such, the majority of the preemptible
future code is compatibility calls to convert between different futures interfaces,
and the thread pool works only with a very old version of the Tokio futures executor.
Porting to a modern futures executor and adding proper support for thread locals
would permit experiments on the latest high-performance systems.

The performance of our implementation could be improved in several ways.  As
Section~\ref{sec:libinger:quantum} noted, one current limitation is our use of a
globally constant preemption quantum.  We could reduce the throughput overhead while
preserving preemption granularity by varying the interval based on the requested
timeout and delaying the first signal for longer-running preemptible functions.  Even
more granular preemption might be achievable by using hardware interrupts directly
instead of paying the overhead of POSIX signals; options include a custom kernel
module or porting to the Dune system~\cite{Belay:osdi2012}.  We saw in
Section~\ref{sec:libgotcha:libtlsblock} that the increased TLS size has an impact on
thread spawn performance.  Incorporating a more robust implementation of the
workaround we prototyped in that section into \textit{libgotcha} would mitigate much
of this effect.  This might also eliminate the need to preallocate TCBs up front to
keep preemptible function launch latencies low.

Another area for improvement is scalability, as ours is currently constrained in
multiple ways.  Preemptible functions' stacks have a fixed size, but leveraging
demand paging would resolve this problem and also avoid having to preallocate them
(Section~\ref{sec:libinger:stacks}).  The fact that we need a dedicated preemption
signal for each preemptible function places a fixed upper bound on parallelism, but
(mis)using glibc's nonstandard \texttt{SIGEV\_THREAD\_ID} feature intended for thread
libraries could make a single signal sufficient (Section~\ref{sec:libinger:signals}).
That the dynamic linker supports a limited number of namespaces determined at compile
time places a fixed upper bound on concurrency, but one could port selective
relinking to an alternative dynamic linker such as drow
(Section~\ref{sec:libgotcha:scalability}).  Our current implementation reduces
runtime latency at the cost of startup time, which is fine for long-running processes
or where workers can be spawned from template ``zygote'' processes, but could pose
issues otherwise.  The performance and scalability improvements proposed thus far are
likely to make pool allocators unnecessary for TCBs and stacks, the largest resources
we preallocate.  Our remaining startup overhead comes from preparing all libsets at
load time, a tradeoff that one would already have to revisit in order to support a
variable number of libsets.

Applying our isolation mechanisms to multi-tenancy situations as proposed in
Chapter~\ref{chap:microservices} would require defense in depth.  Both
\textit{libgotcha} and \textit{libinger} would benefit from using forced
interposition (Section~\ref{sec:libgotcha:interpose}) to replace library functions
that could be used to circumvent selective relinking and preemption in isolated code
regions (e.g., by interfering with signals).  One might also consider expanding the
preemptible functions interface to allow configurable isolation of other actions that
could affect the rest of the application, such as raising exceptions
(Section~\ref{sec:libinger:jumps}).

There are a few enhancements that would improve compatibility, making more unmodified
existing code work with libsets and within preemptible functions.  One could replace
library functions that exhibit unusual signal interruption behavior with wrappers
that hid those differences (Section~\ref{sec:libinger:compatibility}).  One could
detect signals already used by the application to avoid conflicting allocation of the
same signals for preemption (Section~\ref{sec:libinger:signals}).  One could improve
interception of global variable accesses to properly support symbols of any size and
remove the reliance on heuristics that cannot handle certain instruction sequences
(Section~\ref{sec:libgotcha:globals}).  One could consider supporting preemptible
functions that spawned threads and/or forked new processes.  Finally, one could
implement support for nested preemptible functions.

While we have discovered and reported multiple bugs over the course of this project,
we have encountered other issues that may or may not be worth addressing upstream.
In some cases, it was unclear whether issues truly represented a misimplementation of
the relevant specification, or whether they were relevant outside our own specific
and arcane use of runtime features.  It is likely worth revisiting our workarounds
and considering which could be reimplemented upstream to benefit other users.
Examples include \texttt{\_Unwind\_RaiseException()}'s linker namespace limitations
(Section~\ref{sec:libgotcha:interpose}), GDB's reluctance to load symbols from
modules loaded in alternate namespaces (Section~\ref{sec:libgotcha:portability}),
scaling problems in glibc's allocation of TCBs
(Section~\ref{sec:libgotcha:libtlsblock}), certain glibc functions misbehaving in
alternate namespaces (Section~\ref{sec:libinger:compatibility}), and what may be an
off-by-one error in libgcc and libunwind's implementation of the DWARF specification
(Section~\ref{sec:ingerc:boundary}).


\section{Technical challenges}
\label{sec:thatsawrap:challenges}

Manipulating GOTs is not the only thing that gives \textit{libgotcha} its name.  Over
the course of this project, we encountered and had to adapt to a number of tricky
low-level details of other systems.  We also developed some possibly novel insights
and had to create some hackery of our own.

We spent a lot of time comprehending and responding to implementation details of
glibc, and especially its dynamic linker.  One of the early setbacks was its use of
\texttt{NODELETE} shared libraries (Section~\ref{sec:gotchainit}) that monkey patch
one another's internal state (Section~\ref{sec:libgotcha:unintfuns}).  Debugging
unexpected crashes while calling some library functions, we learned about the
nonstandard \texttt{GNU\_IFUNC} relocation type that we had not accounted for because
of its absence from the ABI specification (Section~\ref{sec:libgotcha:functions}).
Once we had more complex programs running, we were surprised to find that exceptions
were causing Rust programs to abort, even though we had built with exception
unwinding and were careful not to allow exceptions to propagate across foreign
function call boundaries (Section~\ref{sec:libinger:jumps}).  The cause turned out
to be poor interplay between the stack unwind library and the dynamic linker's
\texttt{\_dl\_iterate\_phdr()} interface in the presence of calls between linker
namespaces (Section~\ref{sec:libgotcha:interpose}).  When we started to run programs
with multiple libsets, they crashed and we learned about the dynamic library's static
TLS surplus (Section~\ref{sec:libgotcha:scalability}); at the time, tweaking this
required modifying a macro in the dynamic linker sources, but it has since been moved
to a tunable configured via an environment variable.  This is not the only recent
upstream change to affect us (Section~\ref{sec:libgotcha:portability}).  When we
added support for thread-local storage, we found that in order to allocate our own
TCBs without creating POSIX threads, we needed to manually initialize some critical
fields (Section~\ref{sec:libinger:tcbs}).  This led to another issue that briefly
broke threads' ability to signal themselves (Section~\ref{sec:libgotcha:tls}).
Finally, when writing \textit{libas-safe}, we had to grok libc's initialization code
in order to inject a libset switch late enough in startup that it did not leave the
starting libset's C runtime broken (Section~\ref{sec:safety:assafe}).

We also encountered a few dark corners of the Rust language.  Although Rust's ABI is
technically unstable, it mostly follows the C ABI.  However, there are exceptions,
and the lack of stability means there is no single reference of the deviations.
After hours debugging mysterious crashes, we learned the hard way about one such
difference:\@ Rust uses \texttt{\%rdx} as a second return register to store the other
half of fat pointers.  We had to tweak our trampoline code to preserve this register
on return callbacks following uninterruptible code
(Section~\ref{sec:libgotcha:callbacks}).  Once we started implementing preemptible
functions, we quickly ran into double frees caused by the interaction between POSIX
contexts and destructors (Section~\ref{sec:libinger:boilerplate}).  Another thing we
discovered about POSIX contexts is that they contain a self-referential pointer in
the glibc implementation.  This can lead to undefined behavior if they are not heap
allocated or when we need to copy one over another
(Section~\ref{sec:libinger:pausing}).  In such cases, we manually update the
troublesome pointer just before restoring the context.

Implementing \textit{libgotcha} required writing some elaborate low-level code.  To
reroute dynamic function calls based on runtime information, we had to inject code
at the start of the call.  We had to write this code in assembly to avoid clobbering
registers, and design our data structures to be easy to access without
compiler-generated code (Section~\ref{sec:libgotcha:functions}).  This also meant
storing thread-local variables using a TLS model that did not require making calls
into the runtime in order to resolve addresses (Section~\ref{sec:libgotcha:tls}).  To
disambiguate which function was being called, we had to generate executable pages of
stub functions based on a common template, but with slight differences between each
entry (Section~\ref{sec:libgotcha:functions}).  Supporting control library callbacks
required pushing a trampoline onto the stack to mark the call that had prompted the
transition into uninterruptible code  (Section~\ref{sec:libgotcha:callbacks}).  We
had to size the trampoline's stack frame to maintain stack alignment, and incorporate
logic to prevent any libset switches inside the callback from prompting recursive
callbacks.  Intercepting global variable accesses was challenging in a different way,
requiring a difficult-to-debug segmentation fault handler, a dependency on a
disassembler library, and custom heuristics based on patterns we observed in compiled
code (Section~\ref{sec:libgotcha:globals}).  We wanted forced interposition functions
to be able to call the functions they wrapped without manually resolving the
underlying symbol (Section~\ref{sec:libgotcha:interpose}).  Preventing GCC and Clang
from assuming these calls were recursive required a combination of the
\texttt{-fno-optimize-sibling-calls} compiler switch and symbol aliases.

Finally, we had to develop some insights of our own that might prove useful to others
working with signals, POSIX contexts, exceptions, or dynamic linking.  We created a
portable mechanism for directing external signals at particular threads using a
signal pool and convergence algorithm (Section~\ref{sec:libinger:signals}).  We also
discovered a way of safely restoring a POSIX context obtained from a signal handler
(Section~\ref{sec:libinger:resuming}).  In our exploration of automatic resource
cleanup, we sketched out workarounds to some of the problems that have long plagued
asynchronous exception handling (Section~\ref{sec:ingerc:async}).  We designed
algorithms for detecting cross-module dynamic symbol references
(Section~\ref{sec:libgotcha:crossref}) and lazily reinitializing portions of the TLS
area on demand (Section~\ref{sec:libgotcha:tls}).  In extending pointer equality
to selective relinking, we realized that two pointers can be statically equivalent
within a certain context even without knowing which libset their calls will be routed
to at runtime (Section~\ref{sec:libgotcha:functions}).  In the latter section, we
also invented a trick for convincing the dynamic linker to write the address of
lazily-resolved symbol addresses to a custom location.


\section{Lessons for systems builders}
\label{sec:thatsawrap:lessons}

We leave the reader with a few higher-level lessons that have saved us time and pain,
but would have saved us more of each if we had fully appreciated them from the start:
\begin{itemize}
\item You cannot have fine-grained time isolation without fine-grained memory
isolation.

\item Design abstractions modularly and with an eye to other use cases; for instance,
do not try to fold time and memory isolation into a single tightly-coupled primitive
as we almost did.

\item The ability to resume interrupted tasks is a useful feature that improves
composability and is cheaper than cancellation, but it also introduces explicit
concurrency into the task interface.

\item Treat debuggability as a first-order concern.  Include runtime assertions with
descriptive errors, trace safety violations in unsound interfaces at runtime in debug
builds, detect and warn on misuse that could cause confusing or invalid results, make
it easy to disable complex features that may create or obscure problems, and
test and maintain support for running under debugging and diagnostic tools.

\item Periodically teach students and peers about aspects of your system.  Often you
(or they) will discover design shortcomings, interface paper cuts, or pivotal
enhancements.  Even if not, you will come to better understand its workings and be
able to clearly articulate its insights and their broader implications.
\end{itemize}
