\section{Motivation}
\label{sec:motive}

\begin{table}
\begin{center}
\small
\begin{tabular}{lll}
\textbf{Isolation method} & \textbf{Latency} & \textbf{Throughput} \\
\midrule
Process-based & 5 & 200000 \\
Language-based & .5 & 2000000 \\
\end{tabular}
\caption{Performance of isolation methods}
\label{tab:isolation_methods}
\end{center}
\end{table}

Our decision to use language-based isolation is based on two experimental
results that we discuss below. First, process-level isolation is too slow for
microsecond-scale remote functions. Second, high-precision timers on commodity
CPUs allow premption at microsecond-scale. The experiments in this paper were
conducted on an Intel Xeon E5-2683-v4 CPU (16 cores, 2.1~GHz), running
Linux 4.13.0.

\subsection{Process-level isolation is too slow}
We run the following experiment to evaluate the overhead of different isolation
techniques. We use 15 \emph{worker} CPU cores to run microservices. A \emph{host}
process that initiates microservice execution on the worker cores runs on the
16th core. The host schedules up to 15 microservices at a time (i.e., one
per worker core), choosing from a pool of 5000 microservices. It uses one of two
methods to run microservices:

\begin{enumerate}
\item \textbf{Process-based isolation:} Each microservice is a separate process.
At any time, most microservice processes are sleeping while blocked on an IPC
call. The host runs a microservice by waking up its process using IPC. We use
UDP packets for IPC; other IPC methods perform similarly~XXXcite.
\item \textbf{Language-based isolation:} Each worker core runs a single-threaded
\emph{worker process} that is used to run different microservices, one at a time.
In this approach, a worker process runs a microservice by calling its registered
function; we assume that the microservice function can be isolated from the
worker process with language-based isolation techniques that we discuss in
Section XXX. The host schedules microservices on worker processes by sending them
requests on a shared memory queue. Worker processes poll this queue to receive
new requests.
\end{enumerate}

Table~\ref{tab:isolation_methods} shows the latency and throughput achieved
by the two methods. For latency, we measure the median time between when the host
process dispatches a request to a microservice, to when the the service begins
useful work on a worker core. We find that the process-based isolation approach
takes 10\textmu{}s and achieves only 200000 microservice invocations per
second. In contrast, language-based isolation can achieves .1\textmu{}s and
over 2 million invocations per second.

A 10\textmu{}s delay in microservice invocation is a substantial fraction of our
20\textmu{}s RPC latency; the fraction is likely to increase with
improvements in network latency. We therefore conclude that process-based
isolation is too slow for microsecond-scale scheduling. Furthermore, invocation
throughput is also limited by IPC overhead.

\subsection{Intra-process preemption is fast}
With language-based isolation, we run user-provided microservice functions
directly in worker processes. To prevent rogue functions from endlessly blocking
other microservices, we must premept or terminate functions that run for too
long. Assuming that we allow a microservice to run for 100\textmu{}s, we must
preempt rogue functions that run for more than this time. Note that this
preemption interval is orders of magnitude faster than typical operating
system preemption intervals ($\approx$5~ms).

Fortunately, we found that high-precision event timers (HPETs) on modern CPUs
are sufficient for this task. We measure the granularity and reliability of
these timers as follows: We run one thread that installs a timer that fires
periodically at configurable intervals of $T$\textmu{}s. We install a signal
handler that is called on each timer interrupt. Ideally, the signal handler
would be called for the $i^{th}$ time at $T + i$\textmu{}s; we measure the
average difference over 100 iterations between $T + i$ and the actual time
when the signal handler runs for the $i^{th}$ time. We find that the variance
is smaller than XXX\textmu{}s for $T > Y$\textmu{}s. This shows that
intra-process premeption is fast and reliable enough for our needs.

