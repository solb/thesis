\section{Building Blocks}
\label{sec:motive}

\begin{table}
\begin{center}
\small
\begin{tabular}{lrrr}
   & \multicolumn{2}{c}{\textbf{Latency (Âµs)}} & \textbf{Throughput} \\
  \textbf{Isolation method} & Median & 99\% & \textbf{(invocations/sec)} \\
\midrule
Process-based & 8.7 & 27.3 & 288,625 \\
Language-based & 1.2 & 2.0 & 5,418,889 \\
\end{tabular}
\caption{Performance of isolation methods}
\label{tab:isolation_methods}
\end{center}
\end{table}

Our decision to use language-based isolation is based on two experimental
results that we discuss below. First, process-level isolation is too slow for
microsecond-scale remote functions. Second, high-precision timers on commodity
CPUs allow premption at microsecond scale. The experiments in this paper were
conducted on an Intel Xeon E5-2683 v4 CPU (16 cores, 2.1~GHz), running
Linux 4.13.0.

\subsection{Process-level isolation is too slow}
We run the following experiment to evaluate the overhead of different isolation
techniques. We use 14 \emph{worker} CPU cores to run microservices. Another core runs
runs a \emph{host} process that initiates microservice execution on the workers.
The host schedules up to 14 microservices at a time (i.e., one
per worker core), choosing from a pool of 5,000 microservices. It uses one of two
methods to run microservices:
\solb{The term dispatch process is pervasive right now; I need to run through and
change them all.}

\begin{enumerate}
\item \textbf{Process-based isolation:} Each microservice is a separate process.
At any time, most microservice processes are blocked on an IPC
call. The host runs a microservice by waking up its process using IPC. We use
UDP datagrams for IPC; other IPC methods perform similarly~XXXcite.
\item \textbf{Language-based isolation:} Each worker core runs a single-threaded
\emph{worker process} that is used to run different microservices, one at a time.
In this approach, shown in Figure~\ref{fig:sysdesign}, a worker process runs a
microservice by calling its registered
function; we assume that the microservice function can be isolated from the
worker process with language-based isolation techniques that we discuss in
Section XXX. The host schedules microservices on worker processes by sending them
requests on a shared memory queue. Worker processes poll this queue to receive
new requests.
\end{enumerate}

\begin{figure}
\includegraphics[width=\columnwidth]{figs/system}
\caption{Design of the language-based isolation approach.  The host process forwards
requests over a shared-memory queue to a number of worker processes, each of which
runs one user-supplied microservice at a time.}
\label{fig:sysdesign}
\end{figure}

Table~\ref{tab:isolation_methods} shows the latency and throughput achieved
by the two methods. For latency, we measure the time between when the host
process dispatches a request to a microservice and when the service begins
useful work on a worker core. We find that the process-based isolation approach
takes 9\textmu{}s and achieves only 300,000 microservice invocations per
second. In contrast, language-based isolation achieves 1.2\textmu{}s (with a tail
of just 2.0\textmu{}s) and over 5 million invocations per second\footnote{We also
observe that, with trivial microservices, there is a difference in memory
footprint:\ for 5,000 resident microservices, the system memory usage rises by about
2 GiB for the process-based approach, versus just 1.3 for the language-based one.  Of
course, these numbers will substantially rise for larger programs, but we expect the
gap to widen as various microservices include the same libraries.}

A 9\textmu{}s delay in microservice invocation is a substantial fraction of our
20\textmu{}s RPC latency; \mk{What is ``our''?} the fraction is likely to increase with
improvements in network latency. We therefore conclude that process-based
isolation is too slow for microsecond-scale scheduling; furthermore, invocation
throughput is also limited by IPC overhead.

\subsection{Intra-process preemption is fast}
With language-based isolation, we run user-provided microservice functions
directly in worker processes. To prevent rogue functions from endlessly blocking
other microservices, we must premept or terminate functions that run for too
long (e.g., longer than 100\textmu{}s).  This
preemption interval is orders of magnitude faster than typical operating
system preemption intervals ($\approx$5ms).
\mk{Can we add a citation here?}

Fortunately, we found that high-precision event timers (HPETs) on modern CPUs
are sufficient for this task. We measure the granularity and reliability of
these timers as follows: We run one thread that installs a timer that fires
periodically at configurable intervals of $T$\textmu{}s. We install a signal
handler that is called on each timer interrupt. Ideally, the signal handler
would be called for the $i^{th}$ time at $T + i$\textmu{}s; we measure the
average difference over 100 iterations between $T + i$ and the actual time
when the signal handler runs for the $i^{th}$ time. We find that the variance
is smaller than 0.3\textmu{}s for $T > Y$\textmu{}s. This shows that
intra-process premeption is fast and reliable enough for our needs.
\mk{This is a bit confusing.}
