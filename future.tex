\section{Future work}

One of our contributions is asynchronous cancellation, something rarely supported by
the state of the art.  In Section~\ref{sec:libinger:cancel}, we noted our lack of
support for automated resource cleanup; however, we outlined a possible approach for
languages such as Rust, which we intend to investigate further.  Cancellation is
currently
our most expensive operation because of the libset reinitialization described in
Section~\ref{sec:gotchainit}, but we plan to improve this by restoring only the
writeable regions of each module.

Another area for improvement is signal-handling performance optimization: whereas
\textit{Shinjuku} is able to preempt every 5 $\mu$s with a 10\% throughput
penalty~\cite{Kaffes:nsdi2019}, we have observed a similar throughput drop while only
preempting every 20 $\mu$s via our technique~\cite{boucher:atc2018}.  We have not yet
heavily optimized \textit{libinger}, and have reason to believe that doing so will
allow our design to achieve a preemption granularity midway between those figures
for the same throughput cost.  Because \textit{Shinjuku} executes in privilege ring
0, they preempt by issuing interprocessor interrupts (IPIs) directly rather than
using Linux signals.  Their microbenchmarks reveal an IPI:signal latency ratio of
roughly 1:2.5 (1,993 vs.\@ 4,950 CPU cycles), indicating that we are not achieving
peak performance.  Furthermore, a key design difference between our systems suggests
that this ratio probably understates the performance we could achieve.  In their
benchmark, roughly 42\% of cycles are spent sending each signal, a cost we can
amortize because our design uses recurring timer signals to counter warmup effects.
A further 6.9\% of benchmarked cycles are spent propagating the signal between cores,
which should not affect our system because we request the timer signals on the same
core that will receive them rather than using a central watchdog thread to preempt
all workers.  Context switching is likely responsible for most of our unexpected
latency:\@ by writing our signal handler very carefully, we should be able to adopt
the same optimizations they describe (skipping signal mask and floating-point
register swaps).

We believe the lightweight preemptible function abstraction naturally supports
common features of large-scale systems.  For example:  An ad renderer might implement
graceful degradation by rendering frames of an animation in a preemptible function,
dropping unfinished ones to meet its SLO.  An RPC server might preserve work by
processing each request in a preemptible function and memoizing the continuations; if
a request timed out but was later retried by the client, the server could resume
executing it from where it left off.

\solb{Might want to support nested preemptible functions?}
