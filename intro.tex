\section{Introduction}
\label{sec:intro}

After years of struggling to gain adoption, the coroutine has finally become a
mainstream abstraction for cooperatively scheduling function invocations.  Languages
as diverse as C\#, JavaScript, Kotlin, Python, and Rust now support ``async
functions,'' each of which expresses its dependencies by ``awaiting'' a
\textbf{future} (or promise); rather than polling, the language yields if the awaited
result is not yet available.

Key to the popularity of this concurrency abstraction is the ease and seamlessness of
parallelizing it.  Underlying most futures runtimes is some form of green threading
library, typically consisting of a scheduler that distributes work to a pool of
OS-managed worker threads.  Without uncommon kernel
support (e.g., scheduler activations~\cite{anderson:sosp1991}), however, this logical
threading model renders the operating system unaware of individual tasks, meaning
context switches are purely cooperative.  This limitation is common among userland
thread libraries, and illustrates the need for a mechanism for \textit{preemptive}
scheduling at finer granularity than the kernel thread.

In this \paper, we propose an abstraction for calling a function with a timeout:  Once
invoked, the function runs on the same thread as the caller.  Should the function
time out, it is preempted and its execution state is returned as a continuation in
case the caller later wishes to resume it.  The abstraction is exposed via a wrapper
function reminiscent of a thread spawn interface such as \texttt{pthread\_create()}
(except \textit{synchronous}).  Despite their synchronous nature, \textbf{preemptible
functions} are useful to programs that are parallel or rely on asynchronous I/O;
indeed, we later demonstrate how our abstraction composes with futures and threads.

The central challenge of introducing preemption into the contemporary programming
model is supporting existing code.  Despite decades of improvement focused on thread
safety, modern systems stacks still contain critical nonreentrancy, ranging from
devices to the dynamic memory allocator's heap region.
Under POSIX, code that interrupts other user code is safe only if it restricts
itself to calling async-signal-safe (roughly, reentrant)
functions~\cite{signal-safety-manpage}.  This restriction is all too familiar to
those programmers who have written signal handlers:\@ it is what makes it notoriously
difficult to write nontrivial ones.  Preemption of a timed function constitutes its
interruption by the rest of the program.  This implies that \textit{the rest of the
program} should be restricted to calling reentrant functions; needless to say, such
a rule would be
\ifdefined\dga
crippling\xspace
\else
impractical\xspace
\fi.  Addressing this problem is one of the main contributions
of this \paper.  Our main insight here, as shown in Figure~\ref{fig:progsupport}, is
that some libraries are naturally reentrant, while many others can be made reentrant
by automatically cloning their internal state so that preempting one invocation does
not leave the library ``broken'' for concurrent callers.

\begin{figure}
\includegraphics[width=\columnwidth]{figs/progsupport}
\caption{Taxonomy of support for library code.  \textnormal{In practice, we always
apply one of the two mitigations.  Library copying is used by default, and is
discussed in Sections \ref{sec:namespaces} and \ref{sec:libsets}.  Deferred
preemption is needed to preserve the semantics of \texttt{malloc()} and users of
uncopyable resources such as file descriptors or network adapters, and is applied
according to a \whitelist, as described in Section~\ref{sec:uncopyable}.}}
\label{fig:progsupport}
\end{figure}

The most obvious approach to implementing preemptible functions is to map them to
OS threads, where the function would run on a new thread that
could be cancelled upon timeout.  Unfortunately, cancelling a thread is also hard.
\Unix's pthreads provide
asynchronous cancelability, but according to the Linux documentation, it
\begin{quote}
\vspace{-3pt}
is rarely
useful.  Since the thread could be cancelled at \textit{any} time, it cannot safely
reserve resources (e.g., allocating memory with \texttt{malloc()}), acquire mutexes,
semaphores, or locks, and so on...\@ some internal data structures (e.g., the linked
list of free blocks managed by the \texttt{malloc()} family of functions) may be left
in an inconsistent state if cancellation occurs in the middle of the function
call~\cite{pthreadsetcanceltype-manpage}.
\end{quote}
The same is true on Windows, whose API
documentation warns that asynchronously terminating a thread
\begin{quote}
can result in the
following problems: If the target thread owns a critical section, the critical
section will not be released.  If the target thread is allocating memory from the
heap, the heap lock will not be released...
\end{quote}
and goes on from
there~\cite{www-microsoft-terminatethread}.

One might instead seek to implement preemptible functions via the \Unix
\texttt{fork()} call.  Assuming a satisfactory solution to the performance penalty
of this approach, one significant challenge would be providing bidirectional object
visibility and ownership.  In a model where each timed function executes in its own
child process, not only must data allocated by the parent be accessible to the child,
but the opposite must be true as well.  The fact that the child may terminate before
the parent raises allocation lifetime questions.  And all this is
without addressing the difficulty of even calling \texttt{fork()} in a multithreaded
\program:\@ because doing so effectively cancels all threads in the child process
except the calling one, the child process can experience the same problems that
plague thread cancellation~\cite{baumann:hotos2019}.

These na\"ive designs share another shortcoming:\@ in reducing
preemptible functions to a problem of parallelism, they hurt performance by placing
thread creation on the critical path.  Thus, the state-of-the-art abstractions' high
costs limit their composability.  We observe that, when calling a function with
a timeout, it is concurrency alone---and not parallelism---that is fundamental.
Leveraging this key insight, we present a design that \textit{separates interruption
from asynchrony} in order to provide \textit{preemption at granularities in the tens
of microseconds}, orders of magnitude finer than contemporary OS schedulers'
millisecond timescales.  Our research prototype\footnote{Our system is open source;
the code is available from
\href{https://efficient.github.io/\#lpf}{\texttt{efficient.github.io/\#lpf}}.} is
implemented entirely in userland, and
requires neither custom compiler or runtime support nor managed runtime features such
as garbage collection.

This \paper makes three primary contributions:  (1) It proposes function calls that
return a continuation upon preemption, a novel primitive for unmanaged languages.
(2) It introduces selective relinking, a compiler-agnostic approach to automatically
lifting safety restrictions related to nonreentrancy.  (3) It demonstrates how to
support asynchronous function cancellation, a feature missing from state-of-the-art
approaches to preemption, even those that operate at the coarser granularity of a
kernel thread.
