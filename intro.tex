\chapter{Introduction}

The abstraction most fundamental to modern programs is the \textbf{function}, a
section of code that expects zero or more data inputs, performs some computation, and
produces zero or more outputs.  It is a structured control flow primitive that obeys
a strict convention:\@ whenever invoked from one of its \textbf{call sites}, a
function runs from beginning to (one possible) end, at which point execution resumes
in the \textbf{caller} just after the call site.  It is also a \textbf{synchronous}
primitive; that is, all these steps happen sequentially and in order.  Because
processors conceptually implement synchronous computation, scheduling a function is
as trivial as instructing the processor to jump from the call site to its starting
address, then jump back to the (saved) address subsequent to the call site.  Thus,
the program continues executing throughout, with no inherent need for intervention by
an external scheduler or other utility software.

% TODO: Citation on decompression bombs?
Note, however, that just because the program has retained control does not mean the
programmer has.  Precisely because functions represent an abstraction, the programmer
who calls one is not necessarily familiar with its specific implementation.  This can
make it hard to predict the function's duration, yet calling it requires the
programmer to trust it to eventually finish and relinquish control.  The programmer
may have made a promise (e.g., a service-level agreement) that their whole program
will complete within a specified timeframe; unfortunately, they cannot certify their
compliance without breaking the abstraction and examining the internals of each
function they call.  Even then, untrusted or unpredictable input may make the
function's performance characteristics unclear:  Perhaps it solves a problem that is
known to be intractable for certain cases, but such inputs are difficult to identify
\textit{a priori}.  Perhaps it performs format decoding or translation that is
susceptible to attacks such as decompression bombs.  Or perhaps it simply contains
bug that open it to inefficient corner cases or even an infinite loop.

Faced with such problems, the programmer is often tempted to resort to an
\textbf{asynchronous} invocation strategy, whereby the function runs in the
background while the programmer maintains control of the rest of the program.  Common
abstractions following this model include the operating system's own processes and
threads, as well as the threads, coroutines, and futures (i.e., promises) provided by
some libraries and language runtimes.  Any use of asynchronous computation requires
an external scheduler to allocate work.

Here again, the programmer is sacrificing control.  Upon handing execution control to
a scheduler, dependencies are no longer clear from the program's structure and must
be passed to the scheduler by encoding them in synchronization constructs; however,
it is difficult to fully communicate the relevant bits of the application logic
across this abstraction boundary, which can result in unintended resource-sharing
effects such as priority inversion.  Furthermore, each software scheduler is itself a
piece of code, and because its job does not represent useful application work, any
time it spends executing is pure overhead.  Therefore, introducing unnecessary
scheduling necessarily reduces per-processor performance.

In many cases, the \textit{only} tool necessary to ensure timely completion of a
program is preemption.  Instead of confronting this directly, current programming
environments incentivize the programmer to rely on a scheduler to fix the problem,
limiting them to whatever coarse timescales (often milliseconds) the OS scheduler
operates at, or (in the case of userland schedulers) to cooperative scheduling
that doesn't even address the problem of infinite loops.  The goal of this work is to
design and prototype an interface that extends the programming model with simple
preemption, thereby allowing the use of functions without having to break the
abstraction and examine their implementations.  If the function times out, it is
paused so that the programmer can later resume and/or cancel it at the appropriate
time.  Note that such an interface is still inherently concurrent; indeed, it is the
programmer who expresses the schedule describing when to devote time to the timed
code, and how much.


\section{Thesis statement}

\textit{Modern operating systems provide task preemption
as a resource sharing mechanism:\@ when the total number of
threads exceeds the number of processors, the kernel scheduler preempts long-running
or low-priority threads to allow others to run.  Preemption is also useful to
applications in its own right, and its interface
influences the structure and architecture of such programs.
Providing only an asynchronous interface encourages the programmer to leave even
simple scheduling to the operating system, thereby accepting the scheduler's overhead
and coarse resolution.  We introduce a novel
abstraction for preemption at the granularity of a synchronous function call, and
demonstrate that this represents a more efficient and composable interface that
enables new functionality for latency-critical applications, while being both
compatible with the existing systems stack and expressive enough
to encode classic asynchrony primitives.
}


\section{Structure and contributions}

The remaining chapters of this thesis break down our contributions as follows:

\paragraph{Function calls with timeouts (Chapter~\ref{chap:functions})}
We examine prior approaches to running timed code from the literature, triaging the
state of the art's shortcomings.  In the process, we rediscover an ancient interface
for making timed function calls, Scheme engines.  The interface is elegant, but only
capable of handling purely functional code.  By modernizing and enhancing it, we
devise a novel interface for calling impure \textit{preemptible functions}
preemptively.  We set the goal of language agnosticism, aiming to demonstrate support
for unmanaged systems programming languages because they provide few abstractions
that might be unavailable unavailable in other settings.

\paragraph{Nonreentrancy and selective relinking (Chapter~\ref{chap:libgotcha})}
We confront nonreentrancy, a program property that permeates the contemporary systems
stack from the operating system up, and which poses a fundamental safety challenge to
preempting impure code.  To overcome this hazard, we introduce \textit{selective
relinking}, a novel technique that repurposes dynamic linking to establish new
memory isolation boundaries within a process.  Crucially, this new form of isolation
operates at a granularity finer than a kernel thread; in fact, it can be applied at
the level of function calls, as is needed to support preemptible functions.

\paragraph{Rethinking POSIX safety (Chapter~\ref{chap:safety})}
We examine the POSIX safety concepts, the rules that govern what certain parts of a
Unix program may---or may not---do.  In particular, signal handlers are ordinarily
only allowed to call a restricted subset of the available standard functions, and
cancellable threads are conventionally barred from using operating system facilities
altogether.  We show how selective relinking can be applied to lift either of these
restrictions and enable \textit{safe signal handlers} or \textit{asynchronously
cancellable threads}.  While our implementations are only intended as a
demonstration, we find that selective relinking makes both of these seemingly
Herculean tasks simple enough to make for short instructive examples.

\paragraph{Function calls with timeouts, revisited (Chapter~\ref{chap:libinger})}
We return to the topic of preemptible functions and illustrate how to implement them
atop the existing systems stack.  In the process, we specialize what we had designed
as a C interface for the more modern Rust programming language.  The result is a
platform that exhibits both seamless interoperability with legacy code and harmonious
integration with the memory and concurrency safety features of Rust's type system.
The discussion serves both as a demonstration of the kind of considerations that
would go into integrating preemptible functions into other language ecosystems and as
an example of a more advanced use of selective relinking.

\paragraph{Resource cleanup and async unwinding (Chapter~\ref{chap:ingerc})}
We discuss the problem of resource leaks that can occur when asynchronously
cancelling code.  We develop an approach and proof-of-concept system for ensuring the
cleanup of cancelled code's own resources with assistance from the compiler.  We do
this by repurposing exception handling, which requires us to repair
\textit{asynchronous stack unwinding}.  Compilers have struggled to support this
feature, but we devise runtime workarounds to handle the troublesome cases,
introducing only very minimal additional overhead on the normal execution path.

\paragraph{Preemptive userland threading (Chapter~\ref{chap:libturquoise})}
We show how preemptible functions compose with other concurrency abstractions, namely
threads and futures.  We create a \textit{thread library that implements preemptive
scheduling in userland} and still supports unmanaged code.  To accomplish this, we
construct an preemptible future type, which serves as a language-specific adapter of
the preemptible futures interface.  We use this to add preemption to the thread pool
of an existing futures executor.

\paragraph{Preemptive remote procedure calls (Chapter~TODO)}
We observe a pain point common to RPC systems that support impure code:\@ it is
universally incumbent on the developer of a server-side function to periodically
and manually check whether it has exceeded its service-level agreement.  We describe
how a first-year undergraduate student built a \textit{preemptive RPC system} without
this limitation in two months.  Its server uses a single-process architecture but
isolates each request within a preemptible function.  It is also capable of memoizing
both fully- and partially-computed requests; in the latter case, a repeat request
resumes the paused computation from wherever it left off.

\paragraph{Microsecond-scale microservices (Chapter~\ref{chap:microservices})}
We discuss how preemptible functions could be applied to address the problem of
invocation latency in serverless computing.  Whereas contemporary systems typically
place each tenant in its own separate container comprising one or more processes and
a virtual filesystem, we propose consolidating numerous tenants into a single worker
process.  Preemptible functions would provide compute time isolation, whereas memory
isolation would be achieved by requiring tenants to submit only code that could be
proven safe and restricting them to a vetted set of dependencies.

\paragraph{Continuations (Chapter~TODO)}
We summarize our work, including noteworthy technical challenges we faced and
selected lessons for future systems builders.  We propose possible future research
directions.
