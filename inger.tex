\section{Timed functions: \textit{libinger}}
\label{sec:libinger}

To address the literature's shortcomings, we have developed
\textit{libinger}\footnote{In the style of GNU's \textit{libiberty}, we named our
system for the command-line switch used to link against it.  As the proverb goes,
``Don't want your function calls to linger?  Link with \texttt{-linger}.''},
a library that allows timed function dispatch via a small API with
two core functions:
\begin{itemize}
\item \texttt{launch()} invokes an ordinary function $\mathcal{F}$ with an
execution time cap of $T$.  The call to \texttt{launch()} returns when $\mathcal{F}$
completes, or after approximately $T$ microseconds if $\mathcal{F}$ has not returned
by then.  In the latter case, \textit{libinger} returns an opaque continuation
object recording the intermediate execution state.
\item \texttt{resume()} may be called on the continuation generated by a single call
to \texttt{launch()} followed by zero or more calls to \texttt{resume()}.  If the
corresponding $\mathcal{F}$ had not yet returned, \textit{libinger} continues
executing it from the point last reached.
\end{itemize}

\begin{figure}
\begin{lstlisting}[label=lst:ingerapi,caption=Preemptible functions core interface]
struct linger_t {
  bool is_complete;
  cont_t continuation;
};

linger_t launch(Function func,
                u64 time_us,
                void *args);
void resume(linger_t *cont, u64 time_us);
\end{lstlisting}
\end{figure}

Listing~\ref{lst:usage} shows an example usage of \textit{libinger}
in a task queue manager designed to prevent latency-critical tasks from blocking
behind longer-running
ones. The caller invokes a task with a timeout. If the task does not complete
within the allotted time, the caller saves its continuation in the task queue,
proceeds to handling other tasks, and later resumes the first task.

\begin{figure}
\begin{lstlisting}[label=lst:usage, caption=Preemptible function usage example]
linger = launch(task, TIMEOUT, null);
if (!linger.is_complete) {
  // Save @linger to a task queue to
  // resume later
  task_queue.push(linger);
}

// Handle other tasks
...
// Resume @task at some later point
linger = task_queue.pop();
resume(&linger, TIMEOUT);
\end{lstlisting}
\end{figure}

In accordance with our goal of language agnosticism, \textit{libinger} exposes both C
and Rust~\cite{www-rustlang} APIs.  To demonstrate the flexibility and composability
of the preemptible function abstraction, we have also created \textit{libturquoise},
a preemptive userland thread library, by porting an existing futures-based thread
pool to \textit{libinger}.  We discuss this system in Section~\ref{sec:libturquoise}.

Figure~\ref{fig:architecture} shows a dependency graph of the software components
comprising the preemptible functions stack.  The \textit{libinger} library itself is
implemented in approximately 2,500 lines of Rust.  To support calls to nonreentrant
functions, it depends on another library, \textit{libgotcha}, which consists of
another 3,000 lines of C, Rust, and x86-64 assembly.  We now describe the
implementation of \textit{libinger}, beginning with this shared state handling.

\begin{figure}
\begin{center}
\includegraphics[width=0.75\columnwidth]{figs/architecture}
\end{center}
\caption{The preemptible functions software stack.  \textnormal{Rectangular boxes
represent components implementing the preemptible functions abstraction.  Ovals
represent components built on top of these.  Hexagonal boxes show the
required runtime environment.}}
\label{fig:architecture}
\end{figure}


\subsection{Automatic handling of shared state}

As we found in Section~\ref{sec:intro}, a key design challenge facing
\textit{libinger} is the shared state problem:  Suppose a preemptible function
$\mathcal{F}_0$ calls a stateful routine in a third-party library $\mathcal{L}$, and
that $\mathcal{F}_0$ times out and is preempted by \textit{libinger}.  Later, the
user invokes another timed function $\mathcal{F}_0'$, which also calls a stateful
routine in $\mathcal{L}$.  This constituting a concurrency violation,
\textit{libinger} must hide state modifications in $\mathcal{L}$ by $\mathcal{F}_0$
from the execution of $\mathcal{F}_0'$ to avoid undefined behavior.

The problem is actually even worse.  Those familiar with POSIX signals may notice
that, upon a function's timeout, its caller interrupts it.  \textit{The rest of the
program} can therefore be viewed as a signal handler, and would normally be expected
to restrict itself to calling async-signal-safe (roughly, nonreentrant)
functions~\cite{signal-safety-manpage}.

One non-solution to this problem is to instead prevent \textit{preemptible functions}
from
calling into third-party code, but doing so would
severely limit their usefulness (Section~\ref{sec:related}).  We opt instead
to automatically and dynamically create copies of $\mathcal{L}$ to
isolate state from different timed functions.  Making this work on top of
existing systems software required solving many
design and implementation challenges, which we cover when we introduce
\textit{libgotcha} in Section~\ref{sec:libgotcha}.


\subsection{Safe concurrency}

Automatically handling shared state arising from nonreentrant library interfaces is
\textit{only} necessary because the implicit dependency hides the underlying data,
preventing the programmer from applying normal concurrency controls.  Note that a
different problem arises when a programmer explicitly shares state between a
preemptible function and any other part of the program.  Unlike third-party library
authors, this programmer is aware that they are using preemptible functions, a
concurrency mechanism; therefore, the programmer bears responsibility for writing
race-free code (e.g., by using atomics and mutexes wherever necessary).

Using the C interface, one can accidentally introduce a data race that causes
undefined behavior.  The \textit{libinger} Rust API, however, leverages the
language's first-class concurrency support to prevent such mistakes from compiling:\@
\texttt{launch()}'s signature requires the wrapped function to be \texttt{Send} safe
(only reference state in a thread-safe manner)~\cite{www-rustlang-conc}.

While the compiler rejects such broken Rust code, it is still possible to introduce
correctness bugs such as deadlock~\cite{www-rustlang-nu}.  One way to do this is to
block on a mutex held by
the preemptible function's caller (recall that invocation is synchronous, so blocking
in a preemptible function does not cause it to yield!).  It is sometimes necessary to
acquire such a mutex, so \textit{libinger} provides a way to do it:  The API has one
last function, \texttt{pause()}, that is a rough analog of yield.  After performing a
try-lock operation, a preemptible function can call this function to immediately
return to its caller as if it had timed out.  The caller can detect this by checking
a flag on the continuation.


\subsection{Execution stacks}

Recall that, when a preemptible function times out, \textit{libinger} returns a
continuation object.  The caller might pass this object around the program, which
could later call \texttt{resume()} from a different stack frame.  Thus, the
continuation must contain not only the register context, but also the stack
frames belonging to the preemptible function and its callees.  The \texttt{launch()}
function enables this by switching to a new, dedicated stack just before invoking the
user-provided function.

Because of the infeasibility of moving these stacks after a function has started
executing, \textit{libinger} currently heap-allocates large 2-MB stacks so it can
treat them as having fixed size.  The latency of performing these large allocations
was once responsible for an order of magnitude increase in the time overhead of the
\texttt{launch()} operation, so \textit{libinger} now preallocates a large pool of
reusable stacks the first time it is used.


\subsection{Timer interrupts}

\begin{figure}
\includegraphics[width=\columnwidth]{figs/twostacks}
\caption{The stacks before and after a timeout.  \textnormal{Upon discovering
that the preemptible function has exceeded its time bound, the handler jumps into the
\texttt{launch()} function.  Then, \texttt{launch()} returns to the original call
site, removing its stack frame in the process.}}
\solb{Remove the continuations from this diagram and add the handler's stack frame.}
\label{fig:twostacks}
\end{figure}

Whenever \textit{libinger} is executing a user-provided function, we
enable fine-grained timer interrupts to
monitor that function's elapsed running time.  A timer interrupt fires
periodically, causing our signal
handler to be invoked each time.  If the function exceeds its timeout,
this handler saves a continuation by dumping the machine's registers.  It then
performs an unstructured jump out of the signal handler and back into the
\texttt{launch()} or \texttt{resume()} function, switching stacks as it does so.
Figure~\ref{fig:twostacks} shows the two stacks of execution
that are present while the
signal handler is running.

A subsequent \texttt{resume()} call restores the registers from the stored
continuation, thereby jumping back into the signal handler.  The handler
returns, resuming the preemptible function from the instruction that was executing
when the preemption signal arrived.

For simplicity, we use a fixed signal frequency for all preemptible
functions, but this is not fundamental to the design.  In the future, we plan to
adjust each function's frequency based on its timeout, and to delay the first signal
until
shortly before the time limit (in the case of longer-running functions).

\solb{THESIS: Removed discussion of our signal pool trick for notifying specific
POSIX threads.}

\solb{THESIS: Removed discussion of our self-signaling trick for restoring a signal
handler's POSIX context without using \texttt{setcontext()}.}


\subsection{Cancellation}

Should a caller decide not to finish running a timed-out preemptible function, it
must deallocate it.  In Rust this happens implicitly via the \texttt{linger\_t}
type's destructor, whereas users of the C interface are responsible for explicitly
calling the \textit{libinger} \texttt{cancel()} function.

Cancellation cleans up the \textit{libinger} resources allocated by
\texttt{launch()};
however, the current implementation
does not automatically release resources already claimed by the
preemptible function itself.  While the lack of a standard resource deallocation API
makes this inherently hard to do in C, it is possible in languages
such as Rust that support destructors.  For instance, the approach proposed by
Boucher et al.~\cite{boucher:atc2018} could be employed to raise a panic
(exception) on the preemptible function's stack.  This in turn would cause the
language runtime
to unwind each stack frame, invoking local variables' destructors in
the process.


\subsection{Performance goals}

\solb{Move this entire section to Future Work?}

Beyond not making parallelism a necessary condition for preemption, we deliberately
diverged from the design of Shinjuku and RT
in another way:\@ unlike these systems, we make each thread responsible for
its own preemption rather than serving preemption signals from a shared watchdog
thread.  This decision was informed by back-of-the-envelope calculations based on
Shinjuku's comparison of the end-to-end latency of bare-metal interprocessor
interrupts (IPIs) versus Linux signals.

While Shinjuku reports that IPIs take an average of only 1,993 cycles, compared to
4,950 for signals (roughly 1:2.5), their sender/receiver breakdown of the latter
number suggests significant latency savings by avoiding cross-core signaling:
First, 343 of those cycles (6.9\%) are spent propagating the signal between the two
cores; we expect this delay to be nearly absent for a timer interrupt originating at
its destination core's own local interrupt controller.  Second, 2,084 cycles (42\%)
are incurred by the sending core; assuming the interrupt controller supports
periodic timer interrupts at the necessary frequency, this cost does not need to be
paid between each interrupt, suggesting measurable savings here too.  Although
our prototype is not yet optimized to this extent, we expect it is possible for a
system built on intra-thread Linux signals to achieve an average preemption latency
within 2x that of Shinjuku's custom operating system.

Of course, in our design, increasing the accuracy of preemption is a tradeoff:\@ more
frequent timer signals mean a tighter bound on timeout detection, but also a lower
throughput of useful work.  The correct balance certainly depends at least on the
timeout value and size of the function, and merits further study.

\solb{THESIS: Could try to confirm these predicted measurements.}

\solb{THESIS: Could explore strategies for choosing POSIX timer intervals.}
